TODO

Big Refactoring
- merge code from multiple branches
- auto testing and CI become more and more important as the code grows
- transport-trait in libphoenix (with async/.await)
- unify the interface for tcp 
- merge rpc adapter and tcp rpc adapter
- seperate mrpc from phoenix
- doc for public API
- clippy is a must
- error reporting should print stack trace
- mrpc compiler does not consider all the dependent code
- since we have many paths appearing in the configuration, we should have a
  centralized place (one line) to allow users to specify them. Otherwise even we
  developers run into many annoying path/permission problems.
- find a good way to do adaptive polling/eventfd, for both rdma/tcp (is
  that even possible?)
- backend and frontend runtime (tokio scheduling actually makes sense)
- tcp/rdma dynamic switch or at least allow the user choose one at boot
- rdma post send batch
- allow to specify static_resources/addons at program's start
- support for larger than 8MB app (using post_send/recv on private
  heap and read/write)
- more importantly, (merge rdma scheduler with rdma engine), allowing
  chunking in the network pipeline
- more importantly, allow memory sharing because connection buffer size
  should not be proportional to #conns, should be proportional to line rate
- the code in frontend stub is kind of a mess
- overload control
- distributed tracing
- WRef, RRef can be wrapped in Request/Response further (but we still
  suggest the user to know they are using shm version of their data
  structures, right?)
- zbus/handle_request
- really map the shm as read only for user.
- Engine's interface
- live upgrade flush queues -> merge_queue
- mrpc stub multithreaded support / LocalClient LocalServer
- more serious shm data structures (hashmap, ShmCow, ShmBorrow, should
  add two APIs called from std or into std, separate frontend and
  backend two features)
- faster compilation time for libmarshal.so
- more example apps
- integrating into real apps (deepscheduler/byteps, memcached, redis,
  raft, what's the killer apps?)



Policy evals
-[x] content-based custom ACL
-[x] cross-app QoS (video-streaming + background)
- distributed tracing/telemetry
-[x] maintain a eval folder

Real Applications
-[x] eRPC maastree
-[x] thpt is 10x lower than eRPC, why, increase req-window?
-[x] DeathStarBench seems to be running in containers. How to deal with
  this situation?

Prost codegen
-[x] encoding (update this)
-[x] writing the correct codegen, this file should be out-of-tree, give
  it correct visibility
-[x] write mrpc-build, generate the above code
-[x] generate marshal/unmarshal
-[x] dynamic loading
-[x] remove redundant language features and dependencies
-[x] add support for string

Security
- sanity check addresses passed by user
- pass string rather FD to user, and let user to open the shared memory
  only this way r/o permission can be enforced

RPC
-[x] need a multi-threaded throughput test (see if tput can scale linearly)
- server cannot have too many connections, this becomes a problem for
  eRPC's test (both fd recycle and maximal number of fds need fixed)
-[x] too many different things called recv_mr
-[x] *reduce the default 128 buffers to 1 big buffer*
- server cannot specify runtime (or thread pool)
- mrpc::stub::Server is not Send
- merge mrpc::Error into mrpc::Status
- *shared buffer among connections*
- remove the dependencies in thread_local
- Make connect async too
- Rename MessageErased to MessageOpaque
-[x] adding ReclaimRecvBuf back, but in another way
- add a IoReactor in userland
- credit implementation has issues
-[x] Prost codegen
-[x] zero-copy RPC interface
-[x] RPC Trait
-[x] Heap allocator
- RPC scalability: How much more memory is needed for RPC as a service
  this architecture?

Transport Trait
- Design a unified transport trait for both socket and ibverbs
- Let every data path operation return a future, and implement a runtime
  for that
- *Implement a socket datapath*

API
-[x] the return value of a rpc call at the service side should be a Future
-[x] moving RpcMessage from stub to root
- adding prelude (ShmView, RpcMessage)
-[x] mrpc::Status should contains specific error, and be renamed
-[x] return value should not be a &mut RpcMessage
-[x] service handler should not take &mut self

Benchmark Suite
- *collect and print result*
-[x] worker starting order
-[x] build then run
-[x] allow setting timeouts in concrete cases
-[x] auto kill on clean up
-[x] *setup CI (which public CI service has RDMA NIC?) and benchmarks*
- <s>Build a CI pipeline with all kinds of tests and benchmarks</s>
-[x] simplify rpc_hello, add more complex rpc_hello
-[x] also test latency

Engine Framework
-[x] *Implement Packaged scheduling policy* and see if latency is improved
  for small RPCs
-[x] Implement Shared scheduling policy
-[x] move CmEngine and AcceptorEngine to Shared runtime
-[x] suspend the runtime to save CPUs based on indicator
- <s>new challenge: *fault isolation*</s> Updated: doen through careful
  engineering
-[x] futures::executor::block_on seems to start an extra engine, need an
  lazy/sleepy runtime
-[x] *RpcAdapter/CmEngine can only be shut down when the other side has gone.*
-[x] *Change Engine trait to a huge Generator*, all block waitings become
  yields
-[x] *Call an engine's method from another engine*, some engines go to an
  separate runtime, some engines become the member of other engines;
  the original big match arm becomes a series of methods
-[x] Blocking network APIs in transport engine may block the entire
     runtime
-[x] What should Engine::run() return?
- maybe the xatu customer/service framework and queues need to be
  adjusted, separating data/control queues are no more useful
-[x] SchedulingMode::Bundled

Misc
- prune unused features and unused dependencies
-[x] Properly garbage collect CmEngine
- for more flexible IO event notification, need a bus/mailbox/pub-sub.
-[x] *UDP socket send/recv fd must be nonblocking*
- visibility of mods in phoenix backend code
-[x] adding a log (???)
-[x] add span_info back
-[x] create phoenix-trace dir
- <s>use env_logger and minitrace to replace tokio-tracing</s>
-[x] KOALA_LOG[_LEVEL], KOALA_LOG_FILE/DIR
-[x] *add static tracing* points at various points in code for performance
  analysis
-[x] CmIdBuilder::new() -> CmId::builder()
-[x] get configuration from a file to run multiple backends for developing
-[x] simplify ConnParam. Allow to set fields in QpBuilder.
-[x] update the code and directory structure of phoenix_examples
-[x] Add lifetime constraint to CmId in rdmacm library
-[x] Add AsHandle Trait so that open_or_create_resource can do sanity check
     and testing on the same machine
-[x] Remove repeatitive code in libphoenix/cm.rs
-[x] Handle conn_param
-[x] error msg of libphoenix
-[x] add method to access members by reference in libphoenix
-[x] RDMA Read/Write
-[x] upgrade to 1.60, 2021
-[x] add an .cargo config, rr alias
- Also implement handle for CmId, use the pointer as the identifier.
  Now the problem is that pointers are 64-bit. Handle now is only a u32.
- support ibv functions, especially ibv_post_send for batched posting
- update all `trace!`s in TransportEngine::process_cmd
- bench_queues add an option,
  --affinity=[none,hyperthread,numa,crossnuma/inter_numa/inter_cpu]
  --affinity=[casual,l1,l3,mem]

-[x] SAllocEngine and CmEngine should be per-process one engine. optmize
     the number of engines to build.

Shared memory heap
-[x] *check if a read only shm file descriptor can be open with write
     permission and really written*
- need some tests for memory reclamation
- remove file_off (it should be all zero now, given the existence of
  AddressMediator)
-[o] ShmBox, ShmPtr, Coa (Coa to finish)
-[x] shared heap dealloc
- use MMAP_HUGETLB, also reg_mr with huge tlb
-[x] SharedHeapAllocator should not use MemoryRegion any more. The pd and
  rkey, inner_handle are unnecessary. And TCP does not have these
  fields, either.
-[x] need a SharedHeapEngine(SAllocEngine). This engine shares state (mrs) with
  rpc_adapter.
- use pointer strict provenance
-[x] rdma mr.rs handle layout (size + alignment) rather than just size
-[x] find a more efficient way to allocate aligned `shared memory`, maybe
     using map_fixed
-[x] use MAP_FIXED_NOREPLACE
-[x] replace Unique with ShmPtr
-[x] slabmalloc use 1GB huge page
- dyn RpcMessage may some more fields, e.g., to access the content of
  message
-[x] dynamic dispatching is slow, embed meta with dyn RpcMessage
-[x] prost codegen marshal/unmarshal
-[x] prost codegen service interface

RPC init version
- *send/recv is too naive*
-[x] API, req/resp must be moved into RPC (better to allow pass a reference)
-[x] fix bug in runtime.is_spinning()
-[x] releasing reply
-[x] needs to spend a lot of time checking new incoming connections
-[x] get sglist right after jumping into phoenix space
-[x] ODP
-[x] *call rdma-transport directly from rpc_adapter/ulib*
-[x] memory returned by allocate_shm is not page aligned, needs
  improvement
-[x] check incoming connect requests and make Listener::get_request()
  non-blocking
-[x] rpc client side async/.await, basically functionality done
-[x] switch_addr_space to delivery the msg to application
-[x] fill in requset metadata correctly
-[x] resize cq on connection setup/destroy
-[x] credit control on post send
-[x] phoenix configuration, engine paths are not read from phoenix.toml
-[x] make modules in control.rs optional, based on their occurrences in
     phoenix.toml
-[x] error handling at various places (user glue code, marshal/unmarshal)
-[x] Rewrite the marshal/unmarshal and SgList
- MutableResourceTable (global lock and slot lock) (State)
-[x] the lifetime of a reply on the server credit?

Policy
- Implement more engines for global policy

Performance & CPU efficiency
-[x] run latency test for more itertions and use eRPC::Latency util
- try enum_dispatch
- Measure the time spent in userland
-[x] *Packaged scheduling policy*
- *optimize userland latency*
-[x] shortcut query_app_addr
- dashmap access latency seems high (rpc_adapter::check_incoming_connections)
-[x] Change ResoruceTable to one of the implementations of a concurrent
  hashmap (e.g., dashmap).
- GetSendComp() is currently busy spinning
-[x] Save CPU cycles in TransportEngine::run()
-[x] Use FnvHashMap in transport/engine
-[x] Change to Ordering::Relaxed
-[x] Control path is too slow
-[x] balance poll_cq and post_send/recv, reduce redundant poll_cq
    - <s>use seperate queues can work, but still can cause HOL among
      multiple CQs</s>

Testing
- *Crash consistency test*
-[x] *write a multi-thread RPC test*
-[x] test various threading models for phoenix
- One thread post_send/recv, another thread poll_cq
- Multiple threads operate on their own QPs, and poll the CQs associated
  with those QPs
- Run those tests simultaneously with multiple processes

Small example code
- allreduce
-[x] alltoall is so slow, why?

Thread-safety
-[x] Move Resource struct of transport engine up a level.
-[x] Add spinlock to QueuePair, CompletionQueue... in libphoenix
-[x] Most of the resources in transport/engine should be per-user, lock
     or concurrent data structure is needed
-[x] Move CqBuffer from thread_local to lazy_static
- Write a multi-threaded program to test the correctness
-[x] Per process resource management.

Resource Releasing
- *Think over it carefully, rollback the creating resource operation when
  there is exception in the middle using DropGuard *
-[x] implement resource release
-[x] Finally find a solution to deal with Fd/Handle that can come from
     everywhere: use explicit open/close call to update the reference 
     count of the corresponding object at the backend.
-[x] Clean and release the resource after detected a user app is
     disconnected.
	- shmem-ipc
		-[x] <s>Error::Disconnected</s> won't fix
		-[x] remove the blocking send/recv
		-[x] expose current available count to read/write

Memory Registration
-[x] Overlapped memory registration (two non-overlapped regions sharing
     one virtual page), currently, we just avoid this in the example code.
-[x] Couple memory allocation and registration
	-[x] Owned MemoryRegion
	-[x] Type-safe memory region and post_send/recv
-[x] Check if it is possible to avoid rounding up to page

libphoenix interface
-[x] CmId::connect()
-[x] CmIdListener::bind()
-[x] CmIdListener::incoming()
-[x] CmIdListener::accept()

-[x] Multi-NIC. Done, except that resource needs to occupy an entire
     page.

Cloud native
- Let phoenix run on Azure
